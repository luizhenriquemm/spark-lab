{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ab5492-0f74-4ce3-bad1-275b4f8981e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "             .master(\"spark://spark-master:7077\") # Points to the Spark Cluster\n",
    "             .appName('schema-test') # Name the app\n",
    "             .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") # Set external Hive Metastore\n",
    "             .config(\"hive.metastore.warehouse.dir\", \"hdfs://hdfs-namenode:9000/hadoop/warehouse/\") # Set default warehouse dir (legacy) users/hive/warehouse\n",
    "             .config(\"spark.sql.warehouse.dir\", \"hdfs://hdfs-namenode:9000/hadoop/warehouse/\") # Set default warehouse dir\n",
    "             .config(\"hive.metastore.schema.verification\", \"false\") # Prevent some errors\n",
    "             .config(\"fs.defaultFS\", \"hdfs://hdfs-namenode:9000/\") # Set default file system into the HDFS namenode\n",
    "             .enableHiveSupport()\n",
    "             .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe41bede-4b32-4057-a652-83176e566c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|   bronze|\n",
      "|  default|\n",
      "|     gold|\n",
      "|   silver|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e358e9-3b4f-4d86-90ee-3dd69ecd10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze LOCATION 'hdfs://hdfs-namenode:9000/hadoop/warehouse/bronze/'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8384bd8-bb87-45c0-aa3f-1448a6d43bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver LOCATION 'hdfs://hdfs-namenode:9000/hadoop/warehouse/silver/'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75f3afa9-53cf-401f-a63e-d81a08823fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold LOCATION 'hdfs://hdfs-namenode:9000/hadoop/warehouse/gold/'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c10d6f6f-e0d0-434d-b819-ba5eecc03ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_clients_schema = StructType([\n",
    "    StructField(\"client_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"birthdate\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"event\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "bronze_clients_df = spark.createDataFrame([], schema = bronze_clients_schema)\n",
    "schema_str = \", \".join([f\"{x[0]} {x[1]}\" for x in bronze_clients_df.dtypes ])\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS bronze.clients\")\n",
    "spark.sql(f\"CREATE EXTERNAL TABLE IF NOT EXISTS bronze.clients ({schema_str}) USING PARQUET LOCATION 'hdfs://hdfs-namenode:9000/hadoop/warehouse/bronze/clients/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d71140-9f69-452e-972b-1d12839d6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|createtab_stmt                                                                                                                                                                                                                                                                                                                           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CREATE TABLE bronze.clients (\\n  client_id INT,\\n  name STRING,\\n  gender STRING,\\n  birthdate STRING,\\n  address STRING,\\n  city STRING,\\n  state STRING,\\n  event STRING,\\n  timestamp STRING)\\nUSING PARQUET\\nLOCATION 'hdfs://hdfs-namenode:9000/hadoop/warehouse/bronze/clients'\\nTBLPROPERTIES (\\n  'numFilesErasureCoded' = '0')\\n|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show create table bronze.clients\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

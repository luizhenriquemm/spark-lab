{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32bc34e-d075-4ea9-84ed-190b06c4a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "             .master(\"spark://spark-master:7077\") # Points to the Spark Cluster\n",
    "             .appName('lab') # Name the app\n",
    "             .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") # Set external Hive Metastore\n",
    "             .config(\"hive.metastore.warehouse.dir\", \"s3a://minio:9000/datalake/\") # Set default warehouse dir (legacy) users/hive/warehouse\n",
    "             .config(\"spark.sql.warehouse.dir\", \"s3a://minio:9000/datalake/\") # Set default warehouse dir\n",
    "             .config(\"hive.metastore.schema.verification\", \"false\") # Prevent some errors\n",
    "             .config(\"fs.defaultFS\", \"s3a://minio:9000/datalake/\") # Set default file system into the HDFS namenode\n",
    "             .config(\"spark.jars\", \"/opt/bitnami/spark/jars_external/hadoop-aws-3.3.4.jar,/opt/bitnami/spark/jars_external/aws-java-sdk-bundle-1.12.588.jar\")\n",
    "             .enableHiveSupport()\n",
    "             .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "hdp_configs = {\n",
    "    \"fs.s3a.endpoint\": \"http://minio:9000\",\n",
    "    \"fs.s3a.access.key\": \"minio\",\n",
    "    \"fs.s3a.secret.key\": \"minioadmin\",\n",
    "    \"fs.s3a.connection.timeout\": \"600000\",\n",
    "    \"spark.sql.debug.maxToStringFields\": \"100\",\n",
    "    \"fs.s3a.path.style.access\": \"true\",\n",
    "    \"fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"fs.s3a.connection.ssl.enabled\": \"true\"\n",
    "}\n",
    "\n",
    "for k,v in hdp_configs.items():\n",
    "    spark.sparkContext._jsc.hadoopConfiguration().set(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856034a2-7a01-496b-b8bc-f67fe60076a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aebd4f5-6db6-4767-90bf-c064eae91838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   source|    final|      false|\n",
      "|   source|  persons|      false|\n",
      "|   source|    test2|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables from source\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0b3256f-d712-4b52-9fb2-8428ce87b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('ano_cmpt', StringType(), True), \n",
    "    StructField('mes_cmpt', StringType(), True), \n",
    "    StructField('cgc_hosp', StringType(), True), \n",
    "    StructField('munic_res', StringType(), True), \n",
    "    StructField('nasc', DateType(), True), \n",
    "    StructField('sexo', StringType(), True), \n",
    "    StructField('uti_mes_to', StringType(), True), \n",
    "    StructField('uti_int_to', StringType(), True), \n",
    "    StructField('proc_rea', StringType(), True), \n",
    "    StructField('qt_proc', StringType(), True), \n",
    "    StructField('dt_atend', DateType(), True), \n",
    "    StructField('dt_saida', DateType(), True), \n",
    "    StructField('diag_princ', StringType(), True), \n",
    "    StructField('diag_secun', StringType(), True), \n",
    "    StructField('cobranca', StringType(), True), \n",
    "    StructField('natureza', StringType(), True), \n",
    "    StructField('gestao', StringType(), True), \n",
    "    StructField('munic_mov', StringType(), True), \n",
    "    StructField('cod_idade', StringType(), True), \n",
    "    StructField('idade', StringType(), True), \n",
    "    StructField('dias_perm', StringType(), True), \n",
    "    StructField('morte', StringType(), True), \n",
    "    StructField('cnes', StringType(), True), \n",
    "    StructField('fonte', StringType(), True), \n",
    "    StructField('modalidade', StringType(), True), \n",
    "    StructField('nome_uf', StringType(), True), \n",
    "    StructField('nome_municipio', StringType(), True), \n",
    "    StructField('regiao', StringType(), True), \n",
    "    StructField('idhm', FloatType(), True), \n",
    "    StructField('populacao_residente', IntegerType(), True), \n",
    "    StructField('area_unidade_territorial', FloatType(), True), \n",
    "    StructField('diag_princ_desc', StringType(), True), \n",
    "    StructField('diag_secun_desc', StringType(), True), \n",
    "    StructField('diag_princ_detalhes', StructType([\n",
    "        StructField('sub_cat', StringType(), True), \n",
    "        StructField('classificacao', StringType(), True), \n",
    "        StructField('restr_sexo', StringType(), True), \n",
    "        StructField('causa_obito', StringType(), True), \n",
    "        StructField('descricao', StringType(), True), \n",
    "        StructField('desc_abrev', StringType(), True), \n",
    "        StructField('refer', StringType(), True), \n",
    "        StructField('excluidos', StringType(), True)\n",
    "    ]), True), \n",
    "    StructField('diag_secun_detalhes', StructType([\n",
    "        StructField('sub_cat', StringType(), True), \n",
    "        StructField('classificacao', StringType(), True), \n",
    "        StructField('restr_sexo', StringType(), True), \n",
    "        StructField('causa_obito', StringType(), True), \n",
    "        StructField('descricao', StringType(), True), \n",
    "        StructField('desc_abrev', StringType(), True), \n",
    "        StructField('refer', StringType(), True), \n",
    "        StructField('excluidos', StringType(), True)\n",
    "    ]), True), \n",
    "    StructField('feriado', StringType(), True), \n",
    "    StructField('distancia_feriado', IntegerType(), True), \n",
    "    StructField('feriado_info', ArrayType(StructType([\n",
    "        StructField('data', StringType(), True), \n",
    "        StructField('nome', StringType(), True), \n",
    "        StructField('tipo', StringType(), True), \n",
    "        StructField('descricao', StringType(), True), \n",
    "        StructField('uf', StringType(), True), \n",
    "        StructField('municipio', StringType(), True), \n",
    "        StructField('cod_municipio', StringType(), True)\n",
    "    ]), True), True), \n",
    "    StructField('sigla', StringType(), True)\n",
    "])\n",
    "\n",
    "df_final = spark.createDataFrame([], schema = schema)\n",
    "\n",
    "schema_str = \", \".join([f\"{x[0]} {x[1]}\" for x in df_final.drop(\"sigla\").dtypes ])\n",
    "spark.sql(f\"CREATE EXTERNAL TABLE IF NOT EXISTS source.final ({schema_str}) USING PARQUET PARTITIONED BY (sigla string) LOCATION 's3a://datalake/source/final/'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2359e7f5-3d1d-4512-879b-a4f5b5c1c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"msck repair table source.final\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d5944db-3668-484f-9ed8-5b63e65269fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|sigla|   count|\n",
      "+-----+--------+\n",
      "|   SP|67515831|\n",
      "|   RS| 9961350|\n",
      "|   MG| 8143352|\n",
      "|   BA| 5017618|\n",
      "|   SC| 2861516|\n",
      "|   CE|  906485|\n",
      "|   MS|  659648|\n",
      "|   AL|  522891|\n",
      "|   PA|  567822|\n",
      "|   GO|  503891|\n",
      "|   ES|  342183|\n",
      "|   RN|  760980|\n",
      "|   MT|  319959|\n",
      "|   PI|  385786|\n",
      "|   PE|  289395|\n",
      "|   PB|  177462|\n",
      "|   SE|   92552|\n",
      "|   RO|   19372|\n",
      "|   TO|  114201|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(\"source.final\").groupBy(\"sigla\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d54e8e-6834-4dd2-b429-bcbdd86e8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"source.final\").drop(\"diag_princ_detalhes\", \"diag_secun_detalhes\", \"feriado_info\")\n",
    "\n",
    "df.limit(1000).write.mode(\"overwrite\").saveAsTable(\"source.test2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
